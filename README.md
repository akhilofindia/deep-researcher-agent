
# ğŸ“„ Document QA Retriever  

A full-stack application that allows you to **upload, search, and query large documents** (PDFs, text files, resumes, research papers, etc.) using semantic search powered by **FAISS** and **SentenceTransformers**.  

The system splits documents into smart chunks, embeds them, and lets you query with natural language to retrieve relevant text + summaries.  

---

## ğŸš€ Features  

- ğŸ“‚ **Upload documents** (PDF or TXT)  
- ğŸ” **Semantic search** powered by FAISS + MiniLM embeddings  
- ğŸ“ **Smart chunking** of large documents  
- ğŸ“‘ **Source-aware results** (see which document a result came from)  
- ğŸ§¹ **Text cleaning** to remove garbage data from PDFs  
- ğŸŒ **Frontend (React + TypeScript)** for interactive querying  
- âš¡ **Backend (FastAPI)** for document management and retrieval  

---

## ğŸ—ï¸ Project Structure  

```
backend/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ data/              # storage for FAISS index & metadata
â”‚   â”œâ”€â”€ models/            # (reserved for Pydantic models)
â”‚   â”œâ”€â”€ routers/           # (reserved for FastAPI routes)
â”‚   â”œâ”€â”€ services/          # processing / utility logic
â”‚   â”œâ”€â”€ main.py            # main FastAPI app
â”‚   â””â”€â”€ test.py            # test runner
â”‚
â”‚â”€â”€ data/                  # persistent storage
â”‚   â”œâ”€â”€ chunks.pkl
â”‚   â”œâ”€â”€ embeddings.npy
â”‚   â”œâ”€â”€ faiss.index
â”‚   â”œâ”€â”€ metadata.pkl
â”‚   â””â”€â”€ Akhil_resume.pdf   # example file
â”‚
frontend/
â”‚â”€â”€ public/                # static files
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ components/ui/     # React UI components
â”‚   â”‚   â”œâ”€â”€ DocumentManager.tsx
â”‚   â”‚   â”œâ”€â”€ ResearchResults.tsx
â”‚   â”‚   â””â”€â”€ SearchInterface.tsx
â”‚   â”œâ”€â”€ hooks/             # React hooks
â”‚   â”œâ”€â”€ lib/               # utilities
â”‚   â”œâ”€â”€ pages/             # page-level components
â”‚   â”œâ”€â”€ services/          # API service functions
â”‚   â””â”€â”€ store/             # global state management
â”‚
â””â”€â”€ requirements.txt       # Python backend dependencies
```

---

## âš™ï¸ Tech Stack  

### ğŸ”¹ Backend  
- [FastAPI](https://fastapi.tiangolo.com/) â€“ API framework  
- [FAISS](https://faiss.ai/) â€“ vector search engine  
- [SentenceTransformers](https://www.sbert.net/) â€“ embeddings (MiniLM)  
- [pdfplumber](https://github.com/jsvine/pdfplumber) â€“ PDF text extraction  
- [pickle](https://docs.python.org/3/library/pickle.html), NumPy â€“ data persistence  

### ğŸ”¹ Frontend  
- [React](https://react.dev/) + [TypeScript](https://www.typescriptlang.org/)  
- [TailwindCSS](https://tailwindcss.com/) â€“ styling  
- [shadcn/ui](https://ui.shadcn.com/) â€“ UI components  
- [Axios](https://axios-http.com/) â€“ API requests  
- [Zustand](https://github.com/pmndrs/zustand) â€“ state management  

---

## âš¡ Getting Started  

### 1ï¸âƒ£ Clone the repo  

```bash
git clone https://github.com/yourusername/document-qa-retriever.git
cd document-qa-retriever
```

### 2ï¸âƒ£ Backend Setup  

```bash
cd backend
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

pip install -r requirements.txt
```

Run the server:  

```bash
uvicorn app.main:app --reload
```

Server will start at: **http://127.0.0.1:8000**

### 3ï¸âƒ£ Frontend Setup  

```bash
cd frontend
npm install
npm run dev
```

Frontend will run at: **http://localhost:5173** (Vite default).  

---

## ğŸ“‚ Data Flow  

1. Upload document via frontend â†’ sent to backend.  
2. Backend extracts text, chunks it (~500 words), and stores embeddings in FAISS index.  
3. Query is embedded â†’ FAISS retrieves top-K relevant chunks.  
4. Backend synthesizes a short summary from the most relevant sentences.  
5. Results + summary sent to frontend.  

---

## ğŸ” Example Query  

- **Query:** `"What challenges were faced during the expedition?"`  
- **Results:** Relevant document chunks (with similarity scores + source).  
- **Synthesis:** Short summary built from most relevant sentences.  

---

## ğŸ“¦ Requirements  

See [`requirements.txt`](backend/requirements.txt)  

Example:  

```
fastapi
uvicorn
faiss-cpu
sentence-transformers
numpy
pdfplumber
```

---

## ğŸ§ª Testing  

Run backend tests:  

```bash
pytest backend/app/test.py
```

---

## ğŸš€ Future Improvements  

- [ ] Support for **multi-PDF querying at once**  
- [ ] Add **OCR** for scanned PDFs (Tesseract)  
- [ ] Improve **summarization** with LLMs (e.g., GPT / LLaMA)  
- [ ] Add **user authentication**  
- [ ] Cloud storage support (S3, GCS, etc.)  

---

## ğŸ“œ License  

This project is licensed under the MIT License.  
Feel free to fork, modify, and use it for your own projects ğŸš€  
